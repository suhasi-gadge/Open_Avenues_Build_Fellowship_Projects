# -*- coding: utf-8 -*-
"""Metaflow-Pipeline(Task04).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bMnPdIMKSy4R1RnVN446cLw6EHpewsAA

Pipeline
"""

!pip install metaflow pandas spacy transformers datasets evaluate seqeval matplotlib
!python -m spacy download en_core_web_sm

# Commented out IPython magic to ensure Python compatibility.
# %%writefile medical_extraction_flow.py
# from metaflow import FlowSpec, step, Parameter
# import os, json
# import pandas as pd
# import numpy as np
# import spacy
# import matplotlib.pyplot as plt
# from datasets import Dataset
# from transformers import AutoTokenizer, pipeline
# import evaluate
# 
# class MedicalExtractionFlow(FlowSpec):
#     data_path = Parameter("data_path", default="open_ave_data.csv")
#     @step
#     def start(self):
#         self.df = pd.read_csv(self.data_path)
#         self.df = self.df.rename(columns={
#             "ReportText":"text","ExamName":"Examination",
#             "clinicaldata":"Clinical","findings":"Findings",
#             "impression":"Impression"
#         }).dropna(subset=["text"]).reset_index(drop=True)
#         self.df["clean"] = (self.df["text"]
#                                .str.replace(r"\s+"," ",regex=True)
#                                .str.strip().str.strip(":.;"))
#         self.df["clean_match"] = self.df["clean"].str.lower().str.strip(":.; ")
#         self.next(self.preprocess)
# 
#     @step
#     def preprocess(self):
#         nlp = spacy.blank("en")
#         self.df["tokens"] = self.df["clean"].apply(lambda t: [tok.text for tok in nlp(t)])
#         lengths = self.df["tokens"].str.len()
#         plt.hist(lengths, bins=30); plt.xlabel("tokens"); plt.ylabel("reports")
#         plt.savefig("lengths.png"); plt.close()
#         self.next(self.infer)
# 
#     @step
#     def infer(self):
#         ds = Dataset.from_pandas(self.df[["clean"]], preserve_index=False)
#         MODEL = "Qwen/Qwen3-0.6B"
#         tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)
#         ner = pipeline("token-classification", model=MODEL, tokenizer=tokenizer,
#                        aggregation_strategy="simple", device=0)
#         fields = ["Examination","Clinical","Findings","Impression"]
#         def extract_batch(batch):
#             texts = batch["clean"]; ents = ner(texts)
#             out = {f"pred_{f}":[] for f in fields}
#             for e_list in ents:
#                 groups = {f:[] for f in fields}
#                 for e in e_list:
#                     if e["entity_group"] in groups:
#                         groups[e["entity_group"]].append(e["word"].strip())
#                 for f in fields:
#                     out[f"pred_{f}"].append(" ".join(groups[f]).strip())
#             return out
#         ds = ds.map(extract_batch, batched=True, batch_size=16, remove_columns=["clean"])
#         self.df = pd.concat([self.df, ds.to_pandas()], axis=1)
#         self.next(self.evaluate)
# 
#     @step
#     def evaluate(self):
#         fields = ["Examination","Clinical","Findings","Impression"]
#         metrics = {}
#         for f in fields:
#             true = self.df[f].fillna("").str.lower().str.strip(":.; ")
#             pred = self.df[f"pred_{f}"].fillna("").str.lower().str.strip(":.; ")
#             match = true == pred
#             self.df[f"{f}_match"] = match
#             metrics[f] = float(match.mean())
#         metrics["overall_exact_match"] = float(np.mean(list(metrics.values())))
#         self.metrics = metrics
#         print("Metrics:", metrics)
#         self.next(self.save)
# 
#     @step
#     def save(self):
#         self.df.to_csv("results.csv", index=False)
#         with open("metrics.json","w") as f: json.dump(self.metrics, f, indent=2)
#         self.next(self.end)
# 
#     @step
#     def end(self):
#         print("Done. Artifacts: results.csv, metrics.json, lengths.png")
# 
# if __name__=="__main__":
#     MedicalExtractionFlow()
#

import os
os.environ["METAFLOW_USER"] = "your_user_name"

!python medical_extraction_flow.py run

